{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8c7dfd",
   "metadata": {},
   "source": [
    "# Roadmap of this nootebook\n",
    "         Having urls of images -> Donwnload images -> Apply embedding model -> Stock embeddings     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdf0b9",
   "metadata": {},
   "source": [
    "## Notebook Objective\n",
    "\n",
    "This notebook presents a complete pipeline for **collecting, encoding, and storing visual embeddings** from social-media images related to two key topics:  \n",
    "- **“10 septembre”** (September 10th protests)  \n",
    "- **“Reconnaissance France–Palestine”** (recognition of Palestine by France)\n",
    "\n",
    "The objective is to build **reusable, high-quality image embeddings** using state-of-the-art deep-learning models in order to use them in other analysis in this repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14debc9f",
   "metadata": {},
   "source": [
    "# Test Datasets\n",
    "\n",
    "We will test the search engine on two datasets:\n",
    "\n",
    "1. **Recognition of the Palestinian State (08/13 – 08/29)**  \n",
    "   This dataset was collected following France’s recognition of the State of Palestine.  \n",
    "   It includes both **texts and their associated images**, totaling **5,055 images**.\n",
    "\n",
    "2. **September 10 Demonstrations (08/20 – ~10/10)**  \n",
    "   This dataset was collected during the period surrounding the **September 10 protest in France**.  \n",
    "   It also contains **texts and their related images**, totaling **41,942 images**.\n",
    "\n",
    "Only the **image URLs** are stored — the images themselves will be **downloaded dynamically** during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010bdd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import warnings \n",
    "import logging \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"transformer\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"PIL\").setLevel(logging.WARNING)\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()        \n",
    "path = os.getenv(\"path_folder\")\n",
    "\n",
    "\n",
    "from huggingface_hub import login # authenticates with Hugging Face to access gated models like DINOv3.\n",
    "token = os.getenv(\"hugging_face_token\")\n",
    "login(token=token) # authenticates Python environment with Hugging Face account, which is required to download gated models like DINOv3. It can be find on HF\n",
    "\n",
    "\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11654551",
   "metadata": {},
   "source": [
    "## Parametres \n",
    "To know where to stock and from where to download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58020c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "path_folder_images_name = os.path.join(path, \"img_data\")\n",
    "path_folder_images_urls = os.path.join(path, \"img_urls\") # Where are URLs of images\n",
    "path_folder_images_embeddings = os.path.join(path, \"img_embeddings\")\n",
    "\n",
    "subject_10_septembre = '10_septembre' \n",
    "subject_reconnaissance_france_palestine = 'reconnaissance_france_palestine'\n",
    "\n",
    "image_dir_10_septembre = os.path.join(path_folder_images_name, subject_10_septembre)\n",
    "image_dir_reconnaissance_france_palestine = os.path.join(path_folder_images_name, subject_reconnaissance_france_palestine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a765791",
   "metadata": {},
   "source": [
    "- **`path_folder_images_name`** → the **directory path** where the downloaded images will be saved (to be adapted as needed).  \n",
    "- **`path_folder_images_urls`** → the **directory path** where the files containing the **image URLs** are stored (to be adapted as needed).  \n",
    "- **`path_folder_images_embeddings`** → the **directory path** where the embeddings will be saved as parquet file (to be adapted as needed).\n",
    "- **`subject`** → defines the dataset used, either `\"10_septembre\"` or `\"reconnaissance_france_palestine\"` (to be adapted).  \n",
    "- **`image_dir`** → the **subfolder name** inside `path_folder_images_name` where the images will actually be downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a5d0d",
   "metadata": {},
   "source": [
    "## Uploading URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0ba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Septembre Dataset\n",
    "df_urls_10_septembre = pd.read_csv(fr\"{path_folder_images_urls}\\{subject_10_septembre}.csv\")\n",
    "urls_10_septembre = df_urls_10_septembre.url.to_list()\n",
    "\n",
    "# Reconnaissance France Palestine Dataset\n",
    "df_urls_reconnaissance_france_palestine = pd.read_csv(fr\"{path_folder_images_urls}\\{subject_reconnaissance_france_palestine}.csv\")\n",
    "urls_reconnaissance_france_palestine = df_urls_reconnaissance_france_palestine.url.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866d526",
   "metadata": {},
   "source": [
    "## Downloading images (to be executed one time to download images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f0ef3",
   "metadata": {},
   "source": [
    "Once we have URLs we can download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c6fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Septembre Dataset\n",
    "results_10_s, failed_10_s = parallel_download(urls_10_septembre, path_folder_images_name, subject_10_septembre, return_failed_csv=True, csv_name=\"failed_urls_10_septembre.csv\",timeout=2) # Parallel image downloading with error and retry handling\n",
    "\n",
    "# Reconnaissance France Palestine Dataset\n",
    "results_r_f_p, failed_r_f_p = parallel_download(urls_reconnaissance_france_palestine, path_folder_images_name, subject_reconnaissance_france_palestine, return_failed_csv=True, csv_name=\"failed_urls_reconnaissance_france_palestine.csv\", timeout=2) # Parallel image downloading with error and retry handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe1d59e",
   "metadata": {},
   "source": [
    "Since some images on social media may **no longer exist** or may cause **request errors**, setting **`return_failed_csv = True`** enables the creation of a **CSV file** that lists all **URLs that could not be downloaded** during the process.\n",
    "\n",
    "The code above should be executed **only once**.  \n",
    "After running it, all images will be **downloaded locally**, and can then be **reused directly** in subsequent steps without re-downloading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6eda0e",
   "metadata": {},
   "source": [
    "## Applying a sota Models \n",
    "\n",
    "We apply the model **`laion/CLIP-ViT-H-14-laion2B-s32B-b79K`** to generate embeddings for semantic comparison and retrieval.\n",
    "\n",
    "We apply the model **`facebook/dinov3-vith16plus-pretrain-lvd1689m`** to generate embeddings for visual comparison.\n",
    "\n",
    "\n",
    "`CLIP (semantic model): encodes the meaning of an image — useful for text–image retrieval or topic clustering.`\n",
    "\n",
    "`DINO (visual model): encodes purely visual similarity (color, texture, layout, etc.) — ideal for clustering similar pictures, memes, or logos.`\n",
    "### Watch out \n",
    "`facebook/dinov3-vith16plus-pretrain-lvd1689m` is gated on Hugging Face, meaning you need to be logged in to access it. Alternatively, you can use an open version like `facebook/dinov2-large`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf1b9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Modèle laion/CLIP-ViT-H-14-laion2B-s32B-b79K chargé sur cuda\n",
      "Modèle: facebook/dinov3-vith16plus-pretrain-lvd1689m chargé sur cuda\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "processor_sem, model_sem = upload_clip(\"laion/CLIP-ViT-H-14-laion2B-s32B-b79K\")\n",
    "processor_vis, model_vis = upload_dino(\"facebook/dinov3-vith16plus-pretrain-lvd1689m\") #Modèle par défaut: \"facebook/dinov2-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67884da",
   "metadata": {},
   "source": [
    "## Encoding “reconnaissance france palestine” Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea79f1c",
   "metadata": {},
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865d4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing image paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding image batches: 100%|██████████| 315/315 [02:11<00:00,  2.40it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_clip_reconnaissance_france_palestine = encode_with_clip(image_dir=image_dir_reconnaissance_france_palestine, processor=processor_sem, model=model_sem, batch_size=16)\n",
    "df_sem_reconnaissance_france_palestine = dict_clip_reconnaissance_france_palestine['image_embeddings']\n",
    "\n",
    "# Stock embeddings as parquet file\n",
    "df_sem_reconnaissance_france_palestine.to_parquet(fr\"{path_folder_images_embeddings}/{subject_reconnaissance_france_palestine}_CLIP.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5df5af6",
   "metadata": {},
   "source": [
    "### DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a759d1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches: 100%|██████████| 315/315 [02:15<00:00,  2.32it/s]\n"
     ]
    }
   ],
   "source": [
    "df_vis_reconnaissance_france_palestine = encode_with_dino(image_dir=image_dir_reconnaissance_france_palestine, processor=processor_vis, model=model_vis, batch_size=16)\n",
    "\n",
    "# Stock embeddings as parquet file\n",
    "df_vis_reconnaissance_france_palestine.to_parquet(fr\"{path_folder_images_embeddings}/{subject_reconnaissance_france_palestine}_DINO.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a564c2e",
   "metadata": {},
   "source": [
    "## Encoding “10 septembre” Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce74c86",
   "metadata": {},
   "source": [
    "### CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1d2413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing image paths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding image batches: 100%|██████████| 1245/1245 [17:47<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_clip_10_septembre = encode_with_clip(image_dir=image_dir_10_septembre, processor=processor_sem, model=model_sem, batch_size=32)\n",
    "df_sem_10_septembre = dict_clip_10_septembre['image_embeddings']\n",
    "\n",
    "# Stock embeddings as parquet file\n",
    "df_sem_10_septembre.to_parquet(fr\"{path_folder_images_embeddings}/{subject_10_septembre}.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b2137",
   "metadata": {},
   "source": [
    "### DINO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8428c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding batches: 100%|██████████| 2490/2490 [17:23<00:00,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "df_vis_10_septembre = encode_with_dino(image_dir=image_dir_10_septembre, processor=processor_vis, model=model_vis, batch_size=16)\n",
    "\n",
    "# Stock embeddings as parquet file\n",
    "df_vis_10_septembre.to_parquet(fr\"{path_folder_images_embeddings}/{subject_10_septembre}_DINO.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
